# SHL Assessment Recommendation Engine

This project is an **AI-powered assessment recommendation engine** built as part of the **SHL Research Intern â€“ Generative AI Assignment**.  
It intelligently recommends the most relevant **Individual Test Solutions** from SHLâ€™s product catalog based on **free-text user queries**, using **semantic search (embeddings) + metadata-based reranking**.

---

## ğŸ¯ Problem Statement
Given a free-text hiring or assessment requirement query (e.g.,  
> _â€œSoftware engineering coding assessment for freshers with Java skillsâ€_),  
the system must:

- Recommend the most relevant **Individual Test Solutions**
- Exclude packaged job-based assessments
- Return top-K best-fit options with semantic meaning
- Support metadata preferences (Remote / Adaptive / Test Type)
- Produce a **submission.csv** file using query dataset for evaluation

---

## ğŸš€ Key Features
- 377 **Individual Test Solutions scraped** via Playwright
- **Detailed metadata extraction** (description, job levels, test type, remote, adaptive)
- **Vector embeddings** using `all-MiniLM-L6-v2`
- **ChromaDB vector store**
- **FastAPI backend**
- **React + Tailwind UI** (Dark/Light mode)
- **Advanced reranking** with metadata boost scoring
- **CSV output generation for SHL evaluation queries**

---

## ğŸ§  System Architecture
```mermaid
flowchart LR
    %% ====== OFFLINE PIPELINE ======
    subgraph OFFLINE["Offline Data & Embedding Pipeline"]
        A1[Playwright + BeautifulSoup Scraper\n(scrape_shl_catalog.py)] --> A2[catalog_raw.json\n(Individual Test Solutions)]
        A2 --> A3[Detail Scraper\n(scrape_details.py)]
        A3 --> A4[catalog_full.json\n(+ descriptions, job levels)]
        A4 --> A5[Embedding Generator\n(create_embeddings.py)]
        A5 --> A6[Chroma Vector DB\n(collection: shl_products)]
    end

    %% ====== ONLINE RECOMMENDATION FLOW ======
    subgraph ONLINE["Online Recommendation System"]
        U[User in Browser] --> FE[React + Vite + Tailwind UI\n(Dark/Light mode, filters)]
        FE -->|POST /recommend\nAxios| API[FastAPI Backend]

        API -->|Encode query\n(all-MiniLM-L6-v2)| EMB[SentenceTransformer Model]
        EMB -->|Query embedding| VDB[ChromaDB Vector DB]

        VDB -->|Top-N nearest neighbours| RANK[Reranking & Scoring Layer\nSemantic + metadata boosts]
        RANK -->|Top-K results| FE

        FE -->|View Details â†’ SHL URL| U
    end

    %% ====== SUBMISSION GENERATION ======
    subgraph EVAL["Evaluation"]
        DS[Gen_AI Dataset.xlsx] --> SUB[generate_submission.py]
        SUB --> CSV[submission.csv]
    end

## ğŸ§® Recommendation Logic

### Processing Steps
| Step | Action |
|------|--------|
| 1 | Encode query using SentenceTransformer embeddings |
| 2 | Get Top-N semantic matches from ChromaDB |
| 3 | Apply metadata boost scoring |
| 4 | Sort by final score |
| 5 | Return Top-K recommendations |

### ğŸ“Œ Scoring Boost Rules
| Rule | Score |
|------|-------|
| Remote preference match | +0.05 |
| Adaptive preference match | +0.05 |
| Test type match (K/S/P) | +0.10 |

---

## ğŸ— Tech Stack

### Backend
- Python, FastAPI, Uvicorn
- SentenceTransformers (`all-MiniLM-L6-v2`)
- ChromaDB Vector Store
- Playwright + BeautifulSoup
- Pandas, OpenPyXL

### Frontend
- React (Vite)
- TailwindCSS
- Axios
- Dark / Light mode toggle

---

## ğŸ’» How to Run

### 1. Start Backend
```bash
cd backend
conda activate shlrec
uvicorn app.main:app --reload

### 2. Start Frontend
```bash
cd frontend
npm install
npm run dev

### 3. Access Application
Open `http://localhost:5173` in your browser.

### 4. Generate Submission File
```bash
cd backend
python tools/generate_submission.py

### project Structure
```shl-assessment-recommendation-engine/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/main.py
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ tools/generate_submission.py
â”œâ”€â”€ frontend/
â”œâ”€â”€ scraper/
â”œâ”€â”€ submission.csv
â”œâ”€â”€ architecture.png
â””â”€â”€ README.md
```